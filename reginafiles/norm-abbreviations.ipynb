{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/starspace/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/starspace/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/starspace/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/starspace/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/starspace/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/starspace/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/starspace/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/starspace/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/starspace/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/starspace/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/starspace/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/starspace/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import time\n",
    "from tokenizer import split_into_sentences\n",
    "import pos\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import number_help as nh\n",
    "import number_functions as nf\n",
    "import wlinks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import area_dict as ad\n",
    "import currency_dict as cd\n",
    "import distance_dict as dd\n",
    "import electronic_dict as ed\n",
    "import period_dict as pd\n",
    "import rest_dict as rd\n",
    "import time_dict as td\n",
    "import volume_dict as vd\n",
    "import weight_dict as wd\n",
    "import pre_help_dicts as phd\n",
    "import symbols_dict as sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cardinal_ones_tuples as cot\n",
    "import cardinal_thousands_tuples as ctt\n",
    "import cardinal_million_tuples as cmt\n",
    "import cardinal_big_tuples as cbt\n",
    "import ordinal_ones_tuples as oot\n",
    "import ordinal_thousands_tuples as ott\n",
    "import ordinal_million_tuples as omt\n",
    "import ordinal_big_tuples as obt\n",
    "import decimal_thousands_tuples as dtt\n",
    "import fraction_tuples as ft\n",
    "import sport_tuples as st\n",
    "import time_tuples as tt\n",
    "import abbr_functions as af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tuple_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_zip = tuple_rules.half_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[nl]ke[n]-?((g?s?)|([svo]?[fme]?))', ' hálfur', '(1\\\\/2|½)'),\n",
       " ('[nl]ke[o]-?((g?s?)|([svo]?[fme]?))', ' hálfan', '(1\\\\/2|½)'),\n",
       " ('[nl][kvh][ef]þ-?((g?s?)|([svo]?[fme]?))', ' hálfum', '(1\\\\/2|½)'),\n",
       " ('[nl][kh]ee-?((g?s?)|([svo]?[fme]?))', ' hálfs', '(1\\\\/2|½)'),\n",
       " ('(([nl]ven)|([n|l]hf[n|o]))-?((g?s?)|([svo]?[fme]?))', ' hálf', '(1\\\\/2|½)'),\n",
       " ('[nl][k|v][f|e]o-?((g?s?)|([svo]?[fme]?))', ' hálfa', '(1\\\\/2|½)'),\n",
       " ('[nl]veþ-?((g?s?)|([svo]?[fme]?))', ' hálfri', '(1\\\\/2|½)'),\n",
       " ('[nl]vee-?((g?s?)|([svo]?[fme]?))', ' hálfrar', '(1\\\\/2|½)'),\n",
       " ('[nl]he[n|o]-?((g?s?)|([svo]?[fme]?))', ' hálft', '(1\\\\/2|½)'),\n",
       " ('[nl]heþ-?((g?s?)|([svo]?[fme]?))', ' hálfu', '(1\\\\/2|½)'),\n",
       " ('[nl]kfn-?((g?s?)|([svo]?[fme]?))', ' hálfir', '(1\\\\/2|½)'),\n",
       " ('[nl][k|v|h]fe-?((g?s?)|([svo]?[fme]?))', ' hálfra', '(1\\\\/2|½)'),\n",
       " ('^(?![nl][kvh][ef][noþe]-?((g?s?)|([svo]?[fme]?)))[a-záðéíóúýþæö\\\\d\\\\-]+$',\n",
       "  ' hálfur',\n",
       "  '(1\\\\/2|½)'),\n",
       " ('[nl][kvh][ef]n-?((g?s?)|([svo]?[fme]?))', ' einn þriðji', '(1\\\\/3|⅓)'),\n",
       " ('[nl][kvh][ef]o-?((g?s?)|([svo]?[fme]?))', ' einn þriðja', '(1\\\\/3|⅓)'),\n",
       " ('[nl][kvh][ef]þ-?((g?s?)|([svo]?[fme]?))', ' einum þriðja', '(1\\\\/3|⅓)'),\n",
       " ('[nl][kvh][ef]e-?((g?s?)|([svo]?[fme]?))', ' eins þriðja', '(1\\\\/3|⅓)'),\n",
       " ('^(?![nl][kvh][ef][noþe]-?((g?s?)|([svo]?[fme]?)))[a-záðéíóúýþæö\\\\d\\\\-]+$',\n",
       "  ' einn þriðji',\n",
       "  '(1\\\\/3|⅓)'),\n",
       " ('[nl][kvh][ef]n-?((g?s?)|([svo]?[fme]?))', ' einn fjórði', '(1\\\\/4|¼)'),\n",
       " ('[nl][kvh][ef]o-?((g?s?)|([svo]?[fme]?))', ' einn fjórða', '(1\\\\/4|¼)'),\n",
       " ('[nl][kvh][ef]þ-?((g?s?)|([svo]?[fme]?))', ' einum fjórða', '(1\\\\/4|¼)'),\n",
       " ('[nl][kvh][ef]e-?((g?s?)|([svo]?[fme]?))', ' eins fjórða', '(1\\\\/4|¼)'),\n",
       " ('^(?![nl][kvh][ef][noþe]-?((g?s?)|([svo]?[fme]?)))[a-záðéíóúýþæö\\\\d\\\\-]+$',\n",
       "  ' einn fjórði',\n",
       "  '(1\\\\/4|¼)'),\n",
       " ('[nl][kvh][ef]n-?((g?s?)|([svo]?[fme]?))', ' tveir þriðju', '(2\\\\/3|⅔)'),\n",
       " ('[nl][kvh][ef]o-?((g?s?)|([svo]?[fme]?))', ' tvo þriðju', '(2\\\\/3|⅔)'),\n",
       " ('[nl][kvh][ef]þ-?((g?s?)|([svo]?[fme]?))', ' tveimur þriðju', '(2\\\\/3|⅔)'),\n",
       " ('[nl][kvh][ef]e-?((g?s?)|([svo]?[fme]?))', ' tveggja þriðju', '(2\\\\/3|⅔)'),\n",
       " ('^(?![nl][kvh][ef][noþe]-?((g?s?)|([svo]?[fme]?)))[a-záðéíóúýþæö\\\\d\\\\-]+$',\n",
       "  ' tveir þriðju',\n",
       "  '(2\\\\/3|⅔)'),\n",
       " ('[nl][kvh][ef]n-?((g?s?)|([svo]?[fme]?))', ' þrír fjórðu', '(3\\\\/4|¾)'),\n",
       " ('[nl][kvh][ef]o-?((g?s?)|([svo]?[fme]?))', ' þrjá fjórðu', '(3\\\\/4|¾)'),\n",
       " ('[nl][kvh][ef]þ-?((g?s?)|([svo]?[fme]?))', ' þremur fjórðu', '(3\\\\/4|¾)'),\n",
       " ('[nl][kvh][ef]e-?((g?s?)|([svo]?[fme]?))', ' þriggja fjórðu', '(3\\\\/4|¾)'),\n",
       " ('^(?![nl][kvh][ef][noþe]-?((g?s?)|([svo]?[fme]?)))[a-záðéíóúýþæö\\\\d\\\\-]+$',\n",
       "  ' þrír fjórðu',\n",
       "  '(3\\\\/4|¾)')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "half_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import number_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = pos.Tagger(\n",
    "    model_file=\"tagger-v2.0.0.pt\",\n",
    "    device=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbr_dict = json.load(open(\"abbrdict.txt\"))\n",
    "direction_ptrn = \"[SN]?V|N|[SN]?A|S\"\n",
    "direction_dict = json.load(open(\"directiondict.txt\"))\n",
    "denominator_dict = json.load(open(\"denominatordict.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_help_dict = phd.pre_help_dicts\n",
    "area_dict = ad.make_area_dict()\n",
    "currency_dict = cd.make_currency_dict()\n",
    "distance_dict = dd.make_distance_dict()\n",
    "electronic_dict = ed.make_electronic_dict()\n",
    "period_dict = pd.make_period_dict()\n",
    "rest_dict = rd.make_rest_measure_dict()\n",
    "time_dict = td.make_time_dict()\n",
    "volume_dict = vd.make_volume_dict()\n",
    "weight_dict = wd.make_weight_dict()\n",
    "symb_dict = sd.symb_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardinal_thousand_tuples = cot.cardinal_ones_tuples + ctt.cardinal_thousands_tuples\n",
    "cardinal_million_tuples = cardinal_thousand_tuples + cmt.cardinal_million_tuples\n",
    "cardinal_big_tuples = cardinal_million_tuples + cbt.cardinal_big_tuples\n",
    "\n",
    "ordinal_thousand_tuples = oot.ordinal_ones_tuples + ott.ordinal_thousands_tuples + ctt.cardinal_thousands_tuples\n",
    "ordinal_million_tuples = ordinal_thousand_tuples + cmt.cardinal_million_tuples + omt.ordinal_million_tuples\n",
    "ordinal_big_tuples = ordinal_million_tuples + cbt.cardinal_big_tuples + obt.ordinal_big_tuples\n",
    "\n",
    "decimal_thousand_tuples = cardinal_thousand_tuples + dtt.decimal_thousands_tuples\n",
    "\n",
    "decimal_big_tuples = cardinal_big_tuples + dtt.decimal_thousands_tuples\n",
    "\n",
    "fraction_tuples = cardinal_thousand_tuples + ft.fraction_tuples\n",
    "\n",
    "sport_tuples = st.sport_tuples\n",
    "\n",
    "time_tuples = tt.time_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "grein = \"Auknar takmarkanir hefjast á miðnætti í París og víðar í Frakklandi vegna ótta við þriðju bylgju \" + \\\n",
    "        \"kórónuveirunnar. Aðgerðirnar hafa áhrif á um 21 milljón manns sem búa á 16 svæðum í landinu. Þær \" + \\\n",
    "        \"verða ekki ekki eins strangar og áður. Að sögn forsætisráðherrans Jean Castex fær fólk t.a.m. \" + \\\n",
    "        \"að stunda æfingar utandyra, að því er kemur fram á BBC. Þetta var 4. dagur 120. mánaðar, \" + \\\n",
    "        \"300. árs. Á ég 4 krónur, 40.000 krónur eða 234.000.000 krónur? Áttu 1/2 mínútu? Klukkan er \" + \\\n",
    "        \"10:08, klukkan var 07 áðan. Hann átti 23/23 fráköst. Það er hneyksli að KFUM sé ekki búið að skipta \" + \\\n",
    "        \"sér af. Kristján IX. kom til landsins um daginn, bíðum eftir Kristjáni IXIIXIXVIX. Létt & laggott seldi \" + \\\n",
    "        \"hlut sinn þann 02.03.2021. Það er hægt að lesa um það á https://mbl.is/innlent. Leikurinn tók 3-4 tíma. \" + \\\n",
    "        \"Síminn minn er 867 9086.\"\n",
    "\n",
    "sent_grein = list(split_into_sentences(grein))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_abbreviations(sent):\n",
    "    sent = af.replace_all(sent, pre_help_dict)\n",
    "    sent = af.replace_all(sent, abbr_dict)\n",
    "    sent = af.replace_all(sent, direction_dict, direction_ptrn)\n",
    "    sent = af.replace_all(sent, denominator_dict, \"\\/\")\n",
    "    sent = af.replace_all(sent, weight_dict, wd.weight_ptrn)\n",
    "    sent = af.replace_all(sent, distance_dict, dd.distance_ptrn)\n",
    "    sent = af.replace_all(sent, area_dict, ad.area_ptrn)\n",
    "    sent = af.replace_all(sent, volume_dict, vd.volume_ptrn)\n",
    "    sent = af.replace_all(sent, time_dict, td.time_ptrn)\n",
    "    sent = af.replace_all(sent, currency_dict, cd.currency_ptrn)\n",
    "    sent = af.replace_all(sent, electronic_dict, ed.electronic_ptrn)\n",
    "    sent = af.replace_all(sent, rest_dict, rd.rest_ptrn) \n",
    "    sent = af.replace_all(sent, period_dict, pd.period_ptrn)\n",
    "    sent = af.replace_domain(sent.split(), 'other')\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_sentence(sent, domain):\n",
    "    returnsent = \"\"\n",
    "    sentsplit = sent.split()\n",
    "    tagsent = tagger.tag_sent(sentsplit)\n",
    "    split_zip = list(zip(sentsplit, list(tagsent[1:]) + [\"\"]))\n",
    "    for word, nexttag in split_zip:\n",
    "        if re.match(\"[\\d½⅓¼⅔¾]\", word):\n",
    "            #print(f\"number: {word}, tag: {nexttag}\")\n",
    "            word = number_findall(word, nexttag, domain)\n",
    "        if re.match(nh.roman_letters_ptrn, word):\n",
    "            #print(f\"roman letters: {word} tag: {nexttag}\")\n",
    "            word = \" \".join(word)\n",
    "        elif re.match(nh.letters_ptrn, word):\n",
    "            #print(f\"letters: {word} tag: {nexttag}\")\n",
    "            word = \" \".join(word)\n",
    "        elif re.match(wlinks.link_ptrn_all, word):\n",
    "            #print(f\"wlink: {word} tag: {nexttag}\")\n",
    "            word = wlinks.wlink_fun(word)\n",
    "        elif re.match(nh.symbol_ptrn, word):\n",
    "            print(f\"symbol: {word} tag: {nexttag}\")\n",
    "            word = af.replace_all(word, symb_dict, nh.symbol_ptrn)\n",
    "        returnsent += word + \" \"\n",
    "    return returnsent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    " def number_findall(word, tag, domain):\n",
    "    normalized_str = \"\"\n",
    "    if re.findall(nh.ordinal_thousand_ptrn, word):\n",
    "        ordinal_thousand_dict = nf.make_dict(word, nh.int_cols_thousand)\n",
    "        tmpword = nf.fill_dict(word, tag, ordinal_thousand_tuples, ordinal_thousand_dict, nh.int_cols_thousand)\n",
    "\n",
    "    elif re.findall(nh.ordinal_million_ptrn, word):\n",
    "        ordinal_million_dict = nf.make_dict(word, nh.int_cols_million)\n",
    "        tmpword = nf.fill_dict(word, tag, ordinal_million_tuples, ordinal_million_dict, nh.int_cols_million)\n",
    "\n",
    "    elif re.findall(nh.ordinal_big_ptrn, word):\n",
    "        ordinal_big_dict = nf.make_dict(word, nh.int_cols_big)\n",
    "        tmpword = nf.fill_dict(word, tag, ordinal_big_tuples, ordinal_big_dict, nh.int_cols_big)\n",
    "\n",
    "    elif re.findall(nh.cardinal_thousand_ptrn, word):\n",
    "        cardinal_thousand_dict = nf.make_dict(word, nh.int_cols_thousand)\n",
    "        tmpword = nf.fill_dict(word, tag, cardinal_thousand_tuples, cardinal_thousand_dict, nh.int_cols_thousand)\n",
    "\n",
    "    elif re.findall(nh.cardinal_million_ptrn, word):\n",
    "        cardinal_million_dict = nf.make_dict(word, nh.int_cols_million)\n",
    "        tmpword = nf.fill_dict(word, tag, cardinal_million_tuples, cardinal_million_dict, nh.int_cols_million)\n",
    "\n",
    "    elif re.findall(nh.cardinal_big_ptrn, word):\n",
    "        cardinal_big_dict = nf.make_dict(word, nh.int_cols_big)\n",
    "        tmpword = nf.fill_dict(word, tag, cardinal_big_tuples, cardinal_big_dict, nh.int_cols_big)\n",
    "\n",
    "    elif re.findall(nh.decimal_thousand_ptrn, word):\n",
    "        decimal_thousand_dict = nf.make_dict(word, nh.decimal_cols_thousand)\n",
    "        tmpword = nf.fill_dict(word, tag, decimal_thousand_tuples, decimal_thousand_dict, nh.decimal_cols_thousand)\n",
    "\n",
    "    elif re.findall(nh.decimal_big_ptrn, word):\n",
    "        decimal_big_dict = nf.make_dict(word, nh.decimal_cols_big)\n",
    "        tmpword = nf.fill_dict(word, tag, decimal_big_tuples, decimal_big_dict, nh.decimal_cols_big)\n",
    "\n",
    "    elif re.findall(nh.time_ptrn, word):\n",
    "        time_dict = nf.make_dict(word, nh.time_sport_cols)\n",
    "        tmpword = nf.fill_dict(word, tag, time_tuples, time_dict, nh.time_sport_cols)\n",
    "\n",
    "    elif re.findall(nh.fraction_ptrn, word):\n",
    "        #print(\"HALLÓ\")\n",
    "        #print(word)\n",
    "        if domain == 'other' or re.findall(\"½|⅓|⅔|¼|¾\", word):\n",
    "            fraction_dict = make_dict(word, nh.decimal_cols_thousand)\n",
    "            #print(fraction_dict)\n",
    "            tmpword = fill_dict(word, tag, fraction_tuples, fraction_dict, nh.decimal_cols_thousand)\n",
    "            #print(tmpword)\n",
    "        elif domain == 'sport':\n",
    "            sport_dict = nf.make_dict(word, nh.time_sport_cols)\n",
    "            tmpword = nf.fill_dict(word, tag, sport_tuples, sport_dict, nh.time_sport_cols)\n",
    "     \n",
    "    elif re.findall(\"^0\\d\\.$\", word):\n",
    "        tmpword = nf.digit_ord_fun(word)\n",
    "    else:\n",
    "        tmpword = nf.digit_fun(word)\n",
    "    word = tmpword\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dict(word, type_cols):\n",
    "    value_dict = {}\n",
    "    value_dict[word] = {type_cols[0]: \"\"}\n",
    "    for col in type_cols[1:]:\n",
    "        value_dict[word].update({col: \"\"})\n",
    "    return value_dict\n",
    "\n",
    "# Fill the dictionaries with values from appropriate number tuples\n",
    "# Example: word = 4, tuple = (\"[1-4]\", \"nvfn\", \"ones\", \"fjórar\")\n",
    "# The number 4 followed by a feminine, plural, nominative noun becomes fjórar\n",
    "def fill_dict(word, tag, tuples, type_dict, cols):\n",
    "    tmpword = \"\"\n",
    "    for i in range(len(tuples)):\n",
    "        #print(f\"word: {tuples[i][0]}\")\n",
    "        #print(f\"tag: {tuples[i][1]}\")\n",
    "        #print(f\"column: {tuples[i][2]}\")\n",
    "        #print(f\"string: {tuples[i][3]}\")\n",
    "        if re.findall(tuples[i][0], word) and re.findall(tuples[i][1], tag):\n",
    "            type_dict[word][tuples[i][2]] = tuples[i][3]\n",
    "    for col in cols:\n",
    "        tmpword += type_dict[word][col]\n",
    "    return tmpword  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05020713806152344\n",
      "0.4156677722930908\n",
      "0.03890109062194824\n",
      "0.008562088012695312\n",
      "0.006148099899291992\n",
      "0.0009279251098632812\n",
      "0.0074198246002197266\n",
      "0.0007698535919189453\n",
      "0.0007507801055908203\n",
      "0.0008449554443359375\n",
      "0.0014662742614746094\n",
      "0.0008530616760253906\n",
      "0.0009589195251464844\n",
      "0.0006477832794189453\n",
      "0.0008211135864257812\n"
     ]
    }
   ],
   "source": [
    "sent_expand_abbr = []\n",
    "for sent in sent_grein:\n",
    "    start = time.time()\n",
    "    sent = replace_abbreviations(sent)\n",
    "    print(time.time() - start)\n",
    "    sent_expand_abbr.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "symbol: . tag: \n",
      "0.0779719352722168\n",
      "symbol: . tag: \n",
      "0.14043283462524414\n",
      "symbol: . tag: \n",
      "0.06546211242675781\n",
      "symbol: , tag: af\n",
      "letters: BBC tag: pl\n",
      "symbol: . tag: \n",
      "0.07675504684448242\n",
      "symbol: , tag: ta\n",
      "symbol: . tag: \n",
      "0.0921790599822998\n",
      "letters: Á tag: fp1en\n",
      "symbol: , tag: ta\n",
      "symbol: ? tag: \n",
      "0.338515043258667\n",
      "symbol: ? tag: \n",
      "0.19074201583862305\n",
      "symbol: , tag: nveng\n",
      "symbol: . tag: \n",
      "0.0834648609161377\n",
      "symbol: / tag: ta\n",
      "symbol: . tag: \n",
      "0.14224815368652344\n",
      "letters: KFUM tag: svg3en\n",
      "symbol: . tag: \n",
      "0.07090377807617188\n",
      "symbol: , tag: sfg1fn\n",
      "roman letters: IXIIXIXVIX tag: pl\n",
      "symbol: . tag: \n",
      "0.06977486610412598\n",
      "symbol: & tag: lhensf\n",
      "symbol: . tag: \n",
      "0.06896114349365234\n",
      "wlink: https://mbl.is/innlent tag: pl\n",
      "symbol: . tag: \n",
      "0.06926822662353516\n",
      "symbol: . tag: \n",
      "0.0668177604675293\n",
      "symbol: . tag: \n",
      "0.06418704986572266\n"
     ]
    }
   ],
   "source": [
    "sent_expand_no = []\n",
    "for sent in sent_expand_abbr:\n",
    "    start = time.time()\n",
    "    sent = handle_sentence(sent, 'other')\n",
    "    print(time.time() - start)\n",
    "    sent_expand_no.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "symbol: . tag: \n",
      "Leikurinn var  hálf klukkustund . \n",
      "symbol: . tag: \n",
      "Leikurinn varði í  hálfa klukkustund . \n",
      "symbol: . tag: \n",
      "Leikurinn varði frá  hálfri klukkustund . \n",
      "symbol: . tag: \n",
      "Leikurinn var til  hálfrar klukkustundar . \n",
      "symbol: . tag: \n",
      "Leikurinn var  tveimur og hálfri klukkustund . \n",
      "symbol: . tag: \n",
      "Leikurinn varði í  tvær og hálfa klukkustundir . \n",
      "symbol: . tag: \n",
      "Leikurinn varði frá  tveimur og hálfum klukkustundum . \n",
      "symbol: . tag: \n",
      "Leikurinn var til  tveggja og hálfra klukkustunda . \n",
      "symbol: . tag: \n",
      "Leikurinn var  einum þriðja klukkustund . \n",
      "symbol: . tag: \n",
      "Leikurinn varði í  einn þriðja klukkustund . \n",
      "symbol: . tag: \n",
      "Leikurinn varði frá  einum þriðja klukkustund . \n",
      "symbol: . tag: \n",
      "Leikurinn var til  eins þriðja klukkustundar . \n",
      "symbol: . tag: \n",
      "Leikurinn var  tveimur og einum þriðja klukkustund . \n",
      "symbol: . tag: \n",
      "Leikurinn varði í  tvær og einn þriðja klukkustundir . \n",
      "symbol: . tag: \n",
      "Leikurinn varði frá  tveimur og einum þriðja klukkustundum . \n",
      "symbol: . tag: \n",
      "Leikurinn var til  tveggja og eins þriðja klukkustunda . \n",
      "symbol: . tag: \n",
      "Leikurinn var  einn fjórði klukkustund . \n",
      "symbol: . tag: \n",
      "Leikurinn varði í  einn fjórða klukkustund . \n",
      "symbol: . tag: \n",
      "Leikurinn varði frá  einum fjórða klukkustund . \n",
      "symbol: . tag: \n",
      "Leikurinn var til  eins fjórða klukkustundar . \n",
      "symbol: . tag: \n",
      "Leikurinn var  tveimur og einum fjórða klukkustund . \n",
      "symbol: . tag: \n",
      "Leikurinn varði í  tvær og einn fjórða klukkustundir . \n",
      "symbol: . tag: \n",
      "Leikurinn varði frá  tveimur og einum fjórða klukkustundum . \n",
      "symbol: . tag: \n",
      "Leikurinn var til  tveggja og eins fjórða klukkustunda . \n",
      "symbol: . tag: \n",
      "Leikurinn var  tveimur þriðju klukkustund . \n",
      "symbol: . tag: \n",
      "Leikurinn varði í  tveimur þriðju klukkustund . \n",
      "symbol: . tag: \n",
      "Leikurinn varði frá  tveimur þriðju klukkustund . \n",
      "symbol: . tag: \n",
      "Leikurinn var til  tveggja þriðju klukkustundar . \n",
      "symbol: . tag: \n",
      "Leikurinn var  tveimur og tveimur þriðju klukkustund . \n",
      "symbol: . tag: \n",
      "Leikurinn varði í  tvær og tvo þriðju klukkustundir . \n",
      "symbol: . tag: \n",
      "Leikurinn varði frá  tveimur og tveimur þriðju klukkustundum . \n",
      "symbol: . tag: \n",
      "Leikurinn var til  tveggja og tveggja þriðju klukkustunda . \n",
      "symbol: . tag: \n",
      "Leikurinn var  þrír fjórðu klukkustund . \n",
      "symbol: . tag: \n",
      "Leikurinn varði í  þrjá fjórðu klukkustund . \n",
      "symbol: . tag: \n",
      "Leikurinn varði frá  þremur fjórðu klukkustund . \n",
      "symbol: . tag: \n",
      "Leikurinn var til  þriggja fjórðu klukkustundar . \n",
      "symbol: . tag: \n",
      "Leikurinn var  tveimur og þremur fjórðu klukkustund . \n",
      "symbol: . tag: \n",
      "Leikurinn varði í  tvær og þrjá fjórðu klukkustundir . \n",
      "symbol: . tag: \n",
      "Leikurinn varði frá  tveimur og þremur fjórðu klukkustundum . \n",
      "symbol: . tag: \n",
      "Leikurinn var til  tveggja og þriggja fjórðu klukkustunda . \n"
     ]
    }
   ],
   "source": [
    "fractionlist = [\"½\", \"⅓\", \"¼\", \"⅔\", \"¾\"]\n",
    "for item in fractionlist:\n",
    "    print(handle_sentence(\"Leikurinn var \" + item + \" klukkustund .\", 'other'))\n",
    "    print(handle_sentence(\"Leikurinn varði í \" + item + \" klukkustund .\", 'other'))\n",
    "    print(handle_sentence(\"Leikurinn varði frá \" + item + \" klukkustund .\", 'other'))\n",
    "    print(handle_sentence(\"Leikurinn var til \" + item + \" klukkustundar .\", 'other'))\n",
    "    print(handle_sentence(\"Leikurinn var 2\" + item + \" klukkustund .\", 'other'))\n",
    "    print(handle_sentence(\"Leikurinn varði í 2\" + item + \" klukkustundir .\", 'other'))\n",
    "    print(handle_sentence(\"Leikurinn varði frá 2\" + item + \" klukkustundum .\", 'other'))\n",
    "    print(handle_sentence(\"Leikurinn var til 2\" + item + \" klukkustunda .\", 'other'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = \"nvfo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Virkar:\n",
    "1½\n",
    "½\n",
    "    \n",
    "Virkar hálft:\n",
    "\n",
    "\n",
    "Virkar ekki:\n",
    "\n",
    "⅓\n",
    "1⅓\n",
    "¼\n",
    "1¼\n",
    "⅔\n",
    "1⅔\n",
    "¾\n",
    "1¾\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ein og einn þriðji klukkustund um eina og einn þriðja klukkustund frá einni og einum þriðja klukkustund til einnar og eins þriðja klukkustundar\n",
    "\n",
    "ein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Leikurinn fór 2 - 1 .']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(split_into_sentences(\"Leikurinn fór 2-1.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'^([1-9]\\\\d{0,2} ?)?([1-9]\\\\d*\\\\/([2-9]|[1-9]\\\\d+)|(½|⅓|⅔|¼|¾))$'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nh.fraction_ptrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'^(?!1\\\\/2)([1-9]\\\\d?\\\\/[1-9]\\\\d?)$'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nh.sport_ptrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 5), match='22/14'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match(nh.fraction_ptrn, \"22/14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sporttest = \"Hann var með 22/14 fráköst . Leikurinn fór 2 - 1 . Þetta er í mesta lagi 1 4/6 .\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hann',\n",
       " 'var',\n",
       " 'með',\n",
       " '22/14',\n",
       " 'fráköst',\n",
       " '.',\n",
       " 'Leikurinn',\n",
       " 'fór',\n",
       " '2',\n",
       " '-',\n",
       " '1',\n",
       " '.',\n",
       " 'Þetta',\n",
       " 'er',\n",
       " 'í',\n",
       " 'mesta',\n",
       " 'lagi',\n",
       " '1',\n",
       " '4/6',\n",
       " '.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sporttest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-28-0d99d8ed9f2b>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-28-0d99d8ed9f2b>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    if re.findall(nh.fraction_ptrn, )\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for word in sporttest:\n",
    "    if re.findall(nh.fraction_ptrn, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"½\"\n",
    "tag = \"nven\"\n",
    "domain = \"sport\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(split_into_sentences(\"Þetta var 2½ bolli .\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(nh.fraction_ptrn, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_dict = nf.make_dict(word, nh.decimal_cols_thousand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sport_dict = nf.make_dict(\"½\", nh.time_sport_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpword = nf.fill_dict(\"½\", \"nven\", sport_tuples, sport_dict, nh.time_sport_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_dict = nf.make_dict(\"½\", nh.decimal_cols_thousand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpword = nf.fill_dict(word, tag, fraction_tuples, fraction_dict, nh.decimal_cols_thousand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"¼\" == \"¼\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
