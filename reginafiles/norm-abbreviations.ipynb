{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import time\n",
    "from tokenizer import split_into_sentences\n",
    "import pos\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import number_help as nh\n",
    "import number_functions as nf\n",
    "import wlinks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import area_dict as ad\n",
    "import currency_dict as cd\n",
    "import distance_dict as dd\n",
    "import electronic_dict as ed\n",
    "import period_dict as pd\n",
    "import rest_dict as rd\n",
    "import time_dict as td\n",
    "import volume_dict as vd\n",
    "import weight_dict as wd\n",
    "import pre_help_dicts as phd\n",
    "import symbols_dict as sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cardinal_ones_tuples as cot\n",
    "import cardinal_thousands_tuples as ctt\n",
    "import cardinal_million_tuples as cmt\n",
    "import cardinal_big_tuples as cbt\n",
    "import ordinal_ones_tuples as oot\n",
    "import ordinal_thousands_tuples as ott\n",
    "import ordinal_million_tuples as omt\n",
    "import ordinal_big_tuples as obt\n",
    "import decimal_thousands_tuples as dtt\n",
    "import fraction_tuples as ft\n",
    "import sport_tuples as st\n",
    "import time_tuples as tt\n",
    "import abbr_functions as af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = pos.Tagger(\n",
    "    model_file=\"tagger-v2.0.0.pt\",\n",
    "    device=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbr_dict = json.load(open(\"abbrdict.txt\"))\n",
    "direction_ptrn = \"[SN]?V|N|[SN]?A|S\"\n",
    "direction_dict = json.load(open(\"directiondict.txt\"))\n",
    "denominator_dict = json.load(open(\"denominatordict.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_help_dict = phd.pre_help_dicts\n",
    "area_dict = ad.make_area_dict()\n",
    "currency_dict = cd.make_currency_dict()\n",
    "distance_dict = dd.make_distance_dict()\n",
    "electronic_dict = ed.make_electronic_dict()\n",
    "period_dict = pd.make_period_dict()\n",
    "rest_dict = rd.make_rest_measure_dict()\n",
    "time_dict = td.make_time_dict()\n",
    "volume_dict = vd.make_volume_dict()\n",
    "weight_dict = wd.make_weight_dict()\n",
    "symb_dict = sd.symb_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardinal_thousand_tuples = cot.cardinal_ones_tuples + ctt.cardinal_thousands_tuples\n",
    "cardinal_million_tuples = cardinal_thousand_tuples + cmt.cardinal_million_tuples\n",
    "cardinal_big_tuples = cardinal_million_tuples + cbt.cardinal_big_tuples\n",
    "\n",
    "ordinal_thousand_tuples = oot.ordinal_ones_tuples + ott.ordinal_thousands_tuples + ctt.cardinal_thousands_tuples\n",
    "ordinal_million_tuples = ordinal_thousand_tuples + cmt.cardinal_million_tuples + omt.ordinal_million_tuples\n",
    "ordinal_big_tuples = ordinal_million_tuples + cbt.cardinal_big_tuples + obt.ordinal_big_tuples\n",
    "\n",
    "decimal_thousand_tuples = cardinal_thousand_tuples + dtt.decimal_thousands_tuples\n",
    "\n",
    "decimal_big_tuples = cardinal_big_tuples + dtt.decimal_thousands_tuples\n",
    "\n",
    "fraction_tuples = cardinal_thousand_tuples + ft.fraction_tuples\n",
    "\n",
    "sport_tuples = st.sport_tuples\n",
    "\n",
    "time_tuples = tt.time_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "grein = \"Auknar takmarkanir hefjast á miðnætti í París og víðar í Frakklandi vegna ótta við þriðju bylgju \" + \\\n",
    "        \"kórónuveirunnar. Aðgerðirnar hafa áhrif á um 21 milljón manns sem búa á 16 svæðum í landinu. Þær \" + \\\n",
    "        \"verða ekki ekki eins strangar og áður. Að sögn forsætisráðherrans Jean Castex fær fólk t.a.m. \" + \\\n",
    "        \"að stunda æfingar utandyra, að því er kemur fram á BBC. Þetta var 4. dagur 120. mánaðar, \" + \\\n",
    "        \"300. árs. Á ég 4 krónur, 40.000 krónur eða 234.000.000 krónur? Áttu 1/2 mínútu? Klukkan er \" + \\\n",
    "        \"10:08, klukkan var 07 áðan. Hann átti 23/23 fráköst. Það er hneyksli að KFUM sé ekki búið að skipta \" + \\\n",
    "        \"sér af. Kristján IX. kom til landsins um daginn, bíðum eftir Kristjáni IXIIXIXVIX. Létt & laggott seldi \" + \\\n",
    "        \"hlut sinn þann 02.03.2021. Það er hægt að lesa um það á https://mbl.is/innlent. Leikurinn tók 3-4 tíma. \" + \\\n",
    "        \"Síminn minn er 867 9086.\"\n",
    "\n",
    "sent_grein = list(split_into_sentences(grein))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05456900596618652\n",
      "0.42977094650268555\n",
      "0.040628910064697266\n",
      "0.009467124938964844\n",
      "0.007036924362182617\n",
      "0.0011610984802246094\n",
      "0.007748842239379883\n",
      "0.0009388923645019531\n",
      "0.0008440017700195312\n",
      "0.0008668899536132812\n",
      "0.0019741058349609375\n",
      "0.0010471343994140625\n",
      "0.001196146011352539\n",
      "0.0007939338684082031\n",
      "0.0008399486541748047\n"
     ]
    }
   ],
   "source": [
    "def replace_abbreviations(sent)\n",
    "    sent = af.replace_all(sent, pre_help_dict)\n",
    "    sent = af.replace_all(sent, abbr_dict)\n",
    "    sent = af.replace_all(sent, direction_dict, direction_ptrn)\n",
    "    sent = af.replace_all(sent, denominator_dict, \"\\/\")\n",
    "    sent = af.replace_all(sent, weight_dict, wd.weight_ptrn)\n",
    "    sent = af.replace_all(sent, distance_dict, dd.distance_ptrn)\n",
    "    sent = af.replace_all(sent, area_dict, ad.area_ptrn)\n",
    "    sent = af.replace_all(sent, volume_dict, vd.volume_ptrn)\n",
    "    sent = af.replace_all(sent, time_dict, td.time_ptrn)\n",
    "    sent = af.replace_all(sent, currency_dict, cd.currency_ptrn)\n",
    "    sent = af.replace_all(sent, electronic_dict, ed.electronic_ptrn)\n",
    "    sent = af.replace_all(sent, rest_dict, rd.rest_ptrn) \n",
    "    sent = af.replace_all(sent, period_dict, pd.period_ptrn)\n",
    "    sent = af.replace_domain(sent.split(), 'other')\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_sentence(sent):\n",
    "    returnsent = \"\"\n",
    "    sentsplit = sent.split()\n",
    "    tagsent = tagger.tag_sent(sentsplit)\n",
    "    split_zip = list(zip(sentsplit, list(tagsent[1:]) + [\"\"]))\n",
    "    for word, nexttag in split_zip:\n",
    "        if re.match(\"\\d\", word):\n",
    "            word = number_findall(word, nexttag)\n",
    "        if re.match(nh.roman_letters_ptrn, word):\n",
    "            word = \" \".join(word)\n",
    "        elif re.match(nh.letters_ptrn, word):\n",
    "            word = \" \".join(word)\n",
    "        elif re.match(wlinks.link_ptrn_all, word):\n",
    "            word = wlinks.wlink_fun(word)\n",
    "        elif re.match(nh.symbol_ptrn, word):\n",
    "            word = af.replace_all(word, symb_dict, nh.symbol_ptrn)\n",
    "        returnsent += word + \" \"\n",
    "    return returnsent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " def number_findall(word, tag):\n",
    "    normalized_str = \"\"\n",
    "    if re.findall(nh.ordinal_thousand_ptrn, word):\n",
    "        ordinal_thousand_dict = nf.make_dict(word, nh.int_cols_thousand)\n",
    "        tmpword = nf.fill_dict(word, tag, ordinal_thousand_tuples, ordinal_thousand_dict, nh.int_cols_thousand)\n",
    "\n",
    "    elif re.findall(nh.ordinal_million_ptrn, word):\n",
    "        ordinal_million_dict = nf.make_dict(word, nh.int_cols_million)\n",
    "        tmpword = nf.fill_dict(word, tag, ordinal_million_tuples, ordinal_million_dict, nh.int_cols_million)\n",
    "\n",
    "    elif re.findall(nh.ordinal_big_ptrn, word):\n",
    "        ordinal_big_dict = nf.make_dict(word, nh.int_cols_big)\n",
    "        tmpword = nf.fill_dict(word, tag, ordinal_big_tuples, ordinal_big_dict, nh.int_cols_big)\n",
    "\n",
    "    elif re.findall(nh.cardinal_thousand_ptrn, word):\n",
    "        cardinal_thousand_dict = nf.make_dict(word, nh.int_cols_thousand)\n",
    "        tmpword = nf.fill_dict(word, tag, cardinal_thousand_tuples, cardinal_thousand_dict, nh.int_cols_thousand)\n",
    "\n",
    "    elif re.findall(nh.cardinal_million_ptrn, word):\n",
    "        cardinal_million_dict = nf.make_dict(word, nh.int_cols_million)\n",
    "        tmpword = nf.fill_dict(word, tag, cardinal_million_tuples, cardinal_million_dict, nh.int_cols_million)\n",
    "\n",
    "    elif re.findall(nh.cardinal_big_ptrn, word):\n",
    "        cardinal_big_dict = nf.make_dict(word, nh.int_cols_big)\n",
    "        tmpword = nf.fill_dict(word, tag, cardinal_big_tuples, cardinal_big_dict, nh.int_cols_big)\n",
    "\n",
    "    elif re.findall(nh.decimal_thousand_ptrn, word):\n",
    "        decimal_thousand_dict = nf.make_dict(word, nh.decimal_cols_thousand)\n",
    "        tmpword = nf.fill_dict(word, tag, decimal_thousand_tuples, decimal_thousand_dict, nh.decimal_cols_thousand)\n",
    "\n",
    "    elif re.findall(nh.decimal_big_ptrn, word):\n",
    "        decimal_big_dict = nf.make_dict(word, nh.decimal_cols_big)\n",
    "        tmpword = nf.fill_dict(word, tag, decimal_big_tuples, decimal_big_dict, nh.decimal_cols_big)\n",
    "\n",
    "    elif re.findall(nh.fraction_ptrn, word):\n",
    "        fraction_dict = nf.make_dict(word, nh.decimal_cols_thousand)\n",
    "        tmpword = nf.fill_dict(word, tag, fraction_tuples, fraction_dict, nh.decimal_cols_thousand)\n",
    "\n",
    "    elif re.findall(nh.time_ptrn, word):\n",
    "        time_dict = nf.make_dict(word, nh.time_sport_cols)\n",
    "        tmpword = nf.fill_dict(word, tag, time_tuples, time_dict, nh.time_sport_cols)\n",
    "\n",
    "    elif re.findall(nh.sport_ptrn, word):\n",
    "        sport_dict = nf.make_dict(word, nh.time_sport_cols)\n",
    "        tmpword = nf.fill_dict(word, tag, sport_tuples, sport_dict, nh.time_sport_cols)\n",
    "\n",
    "    elif re.findall(\"^0\\d\\.$\", word):\n",
    "        tmpword = nf.digit_ord_fun(word)\n",
    "\n",
    "    else:\n",
    "        tmpword = nf.digit_fun(word)\n",
    "    word = tmpword\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09571099281311035\n",
      "0.13285398483276367\n",
      "0.06630396842956543\n",
      "0.08393383026123047\n",
      "0.09348607063293457\n",
      "0.313190221786499\n",
      "0.1851646900177002\n",
      "0.08957314491271973\n",
      "0.12955904006958008\n",
      "0.06879210472106934\n",
      "0.06743884086608887\n",
      "0.06951785087585449\n",
      "0.06721377372741699\n",
      "0.06266593933105469\n",
      "0.06692194938659668\n"
     ]
    }
   ],
   "source": [
    "sent_expand_no = []\n",
    "for sent in sent_expand_abbr:\n",
    "    start = time.time()\n",
    "    sent = handle_sentence(sent)\n",
    "    print(time.time() - start)\n",
    "    sent_expand_no.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Auknar takmarkanir hefjast á miðnætti í París og víðar í Frakklandi vegna ótta við þriðju bylgju kórónuveirunnar . ',\n",
       " 'Aðgerðirnar hafa áhrif á um  tuttugu og eina milljón manns sem búa á  sextán svæðum í landinu . ',\n",
       " 'Þær verða ekki ekki eins strangar og áður . ',\n",
       " 'Að sögn forsætisráðherrans Jean Castex fær fólk til að mynda að stunda æfingar utandyra , að því er kemur fram á B B C . ',\n",
       " 'Þetta var  fjórði dagur hundrað og tuttugasta mánaðar ,  þrjú hundruðasta árs . ',\n",
       " 'Á ég  fjórar krónur ,  fjörutíu þúsund krónur eða  tvö hundruð þrjátíu og fjórar milljónir krónur ? ',\n",
       " 'Áttu  hálfa mínútu ? ',\n",
       " 'Klukkan er  tíu núll átta , klukkan var núll  sjö áðan . ',\n",
       " 'Hann átti  tuttugu og þrjú skástrik  tuttugu og þrjú fráköst . ',\n",
       " 'Það er hneyksli að K F U M sé ekki búið að skipta sér af . ',\n",
       " 'Kristján níundi kom til landsins um daginn , bíðum eftir Kristjáni I X I I X I X V I X . ',\n",
       " 'Létt og laggott seldi hlut sinn þann núll annan núll þriðja  tvö þúsund tuttugu og eitt . ',\n",
       " 'Það er hægt að lesa um það á h t t p s tvípunktur skástrik skástrik m b l punktur i s skástrik i n n l e n t . ',\n",
       " 'Leikurinn tók  þrjú til  fjóra tíma . ',\n",
       " 'Síminn minn er  átta sex sjö <sil> níu núll átta sex . ']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_expand_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
